{"cells":[{"cell_type":"markdown","metadata":{"id":"2sHBmNhkrTGU"},"source":["##1. Installing Libraries and extracting Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfXahbB7HtAP"},"outputs":[],"source":["!pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RviwfkjkHtAQ"},"outputs":[],"source":["!pip install pycocotools"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOgOfX1fHtAR"},"outputs":[],"source":["!pip install --upgrade scikit-image scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CadV410NHtAR"},"outputs":[],"source":["import os\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.colors as colors\n","import seaborn as sns\n","import numpy as np\n","\n","from random import shuffle\n","from PIL import Image\n","\n","from pycocotools.coco import COCO"]},{"cell_type":"markdown","metadata":{"id":"lf_YNNLUrmYZ"},"source":["##2. Extracting Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvcfnizeHtAR","executionInfo":{"status":"ok","timestamp":1763337775895,"user_tz":300,"elapsed":17584,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"0ec7f894-f109-4455-809e-59ff09708510"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkYRQK3sHtAR"},"outputs":[],"source":["\n","# Load COCO annotation file (you can also use the test file)\n","!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","!unzip -q annotations_trainval2017.zip -d /content/drive/MyDrive/COCO_dataset/annotations\n","\n","# Initialize COCO API for instance annotations\n","annFile = '/content/drive/MyDrive/COCO_dataset/annotations/annotations/instances_train2017.json'\n","coco = COCO(annFile)"]},{"cell_type":"markdown","metadata":{"id":"697bdd7f"},"source":["I have added a cell to mount your Google Drive. Please run it and authorize Colab to access your Drive.\n","\n","Now, I will modify the code in cell `E7SYS1ZFrFoo` to extract the annotations to `/content/drive/MyDrive/COCO_dataset/annotations` and update the `annFile` variable to reflect this path."]},{"cell_type":"markdown","metadata":{"id":"a3793f6b"},"source":["Here is the code to load COCO annotations and display the categories.\n","\n","**Important:** The `annotation_path` variable needs to be set to the actual path of your COCO annotation file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H3tUZnJnHtAS"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjSlY5r5HtAS"},"outputs":[],"source":["ANNOT_URL = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n","ANNOT_DIR = \"./annotations\"\n","ANNOT_FILE = f\"{ANNOT_DIR}/annotations/instances_train2017.json\"\n","\n","if not os.path.exists(ANNOT_FILE):\n","    !wget -q $ANNOT_URL -O annotations.zip\n","    !unzip -q annotations.zip -d $ANNOT_DIR\n","\n","# --- Step 4: Initialize COCO API ---\n","coco = COCO(ANNOT_FILE)\n","\n","# --- Step 5: Get all categories ---\n","cat_ids = coco.getCatIds()\n","cats = coco.loadCats(cat_ids)\n","\n","# --- Step 6: For each category, count how many images belong to it ---\n","category_counts = []\n","for cat in cats:\n","    img_ids = coco.getImgIds(catIds=[cat['id']])\n","    category_counts.append({\n","        'Category': cat['name'],\n","        'Supercategory': cat['supercategory'],\n","        'Num_Images': len(img_ids)\n","    })\n","\n","# --- Step 7: Display in tabular format ---\n","df = pd.DataFrame(category_counts).sort_values(by='Num_Images', ascending=False).reset_index(drop=True)\n","\n","# Set Pandas display options to ensure tabular view\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', 1000)\n","\n","# --- Step 8: Display nicely ---\n","from IPython.display import display\n","display(df.style.set_properties(**{'text-align': 'center'}))\n","\n","# Optional: quick summary\n","print(f\"\\nTotal Categories: {len(df)}\")\n","unique_imgs = len(set(sum([coco.getImgIds(catIds=[c['id']]) for c in cats], [])))\n","print(f\"Total Unique Images (approx, may overlap): {unique_imgs}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5ecxheyHtAT"},"outputs":[],"source":["from pycocotools.coco import COCO\n","import pandas as pd\n","import requests\n","\n","# Load captions annotation file\n","!wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","!unzip -q annotations_trainval2017.zip -d ./annotations\n","\n","annFile = './annotations/annotations/captions_train2017.json'\n","coco_caps = COCO(annFile)\n","\n","# Get image-caption pairs (limit to 2000 for now)\n","anns = coco_caps.loadAnns(coco_caps.getAnnIds())[:2000]\n","data = []\n","for a in anns:\n","    img = coco_caps.loadImgs(a['image_id'])[0]\n","    data.append({\n","        \"image_url\": img['coco_url'],\n","        \"caption\": a['caption']\n","    })\n","\n","df = pd.DataFrame(data)\n","df.head()\n"]},{"cell_type":"markdown","metadata":{"id":"-7r7e2QLIoy-"},"source":["##3. Model Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3jrFd5pHtAT"},"outputs":[],"source":["!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skNhN84sHtAT"},"outputs":[],"source":["# import torch\n","# import clip\n","# from PIL import Image\n","\n","# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","# text_inputs = torch.cat([clip.tokenize(df['caption'].iloc[i]) for i in range(5)]).to(device)\n","# with torch.no_grad():\n","#     text_features = model.encode_text(text_inputs)\n","# print(\"Embedding shape:\", text_features.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ueM0uU0HtAT"},"outputs":[],"source":["import pandas as pd\n","from pycocotools.coco import COCO\n","\n","# Ensure annotations directory exists\n","ANNOT_DIR = './annotations'\n","if not os.path.exists(ANNOT_DIR):\n","    os.makedirs(ANNOT_DIR)\n","\n","# Download and unzip the annotations file if not already present\n","ANNOT_ZIP = 'annotations_trainval2017.zip'\n","if not os.path.exists(ANNOT_ZIP):\n","    !wget -q http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","!unzip -o -q annotations_trainval2017.zip -d {ANNOT_DIR} # -o flag to overwrite without prompting\n","\n","# Define the path to the captions annotation file\n","captions_ann_file = f'{ANNOT_DIR}/annotations/captions_train2017.json'\n","\n","# Initialize COCO API for captions\n","coco_caps = COCO(captions_ann_file)\n","\n","# Get image-caption pairs (limit to 2000 for now, as in the original code)\n","anns = coco_caps.loadAnns(coco_caps.getAnnIds())[:2000]\n","\n","data = []\n","for a in anns:\n","    img = coco_caps.loadImgs(a['image_id'])[0]\n","    data.append({\n","        \"image_url\": img['coco_url'],\n","        \"caption\": a['caption']\n","    })\n","\n","caption_df = pd.DataFrame(data)\n","\n","print(\"Caption DataFrame created successfully with columns:\", caption_df.columns.tolist())\n","display(caption_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wA3EM6aRHtAT"},"outputs":[],"source":["import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","# Use caption_df that was created in the previous cell\n","text_inputs = torch.cat([clip.tokenize(caption_df['caption'].iloc[i]) for i in range(5)]).to(device)\n","with torch.no_grad():\n","    text_features = model.encode_text(text_inputs)\n","print(\"Embedding shape:\", text_features.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J16daU1rHtAU"},"outputs":[],"source":["# --- STEP 1: Install Dependencies ---\n","!pip install -q diffusers==0.31.0 transformers accelerate torch torchvision safetensors\n","\n","# --- STEP 2: Imports ---\n","from diffusers import StableDiffusionPipeline\n","import torch\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# --- STEP 3: Load Pretrained Stable Diffusion Model ---\n","model_id = \"runwayml/stable-diffusion-v1-5\"\n","pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n","pipe = pipe.to(\"cuda\")\n","\n","# --- STEP 4: Function to Generate Room Image ---\n","def generate_room(room_type, size, objects_list, style=\"modern\"):\n","    prompt = f\"A {style} {room_type} of size {size}, decorated with {', '.join(objects_list)}, realistic lighting, 4K interior render\"\n","    print(f\"\\nPrompt ‚Üí {prompt}\")\n","    image = pipe(prompt, num_inference_steps=30, guidance_scale=8.5).images[0]\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()\n","    return image\n","\n","# --- STEP 5: Example Run ---\n","generate_room(\n","    room_type=\"kitchen\",\n","    size=\"10x12 ft\",\n","    objects_list=[\"dining table\", \"refrigerator\", \"microwave\", \"plant\"],\n","    style=\"cozy modern\"\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRek_nbpHtAU"},"outputs":[],"source":["# --- Step 1: Install dependencies (run once per session) ---\n","!pip install -q diffusers transformers accelerate safetensors torch torchvision\n","\n","# --- Step 2: Import and load model ---\n","from diffusers import StableDiffusionPipeline\n","import torch\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16\n",").to(\"cuda\")\n","\n","# --- Step 3: Custom user prompt ---\n","prompt = input(\"Enter your prompt (e.g., 'A cozy 12x10 kitchen with fridge and plants'): \")\n","\n","# --- Step 4: Generate and display ---\n","image = pipe(prompt, guidance_scale=7.5, num_inference_steps=30).images[0]\n","image.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7fEYQTpHtAU"},"outputs":[],"source":["base_prompt = input(\"Enter base idea (e.g., 'modern kitchen'): \")\n","categories = [\"refrigerator\", \"dining table\", \"lamp\"]\n","prompt = f\"A {base_prompt} with {', '.join(categories)}, 4K photo\"\n","print(\"Final prompt:\", prompt)\n","\n","image = pipe(prompt, guidance_scale=7.5, num_inference_steps=30).images[0]\n","from IPython.display import display\n","display(image)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dDlTf7eHtAU"},"outputs":[],"source":["import gradio as gr\n","\n","def generate(prompt):\n","    image = pipe(prompt, guidance_scale=7.5, num_inference_steps=30).images[0]\n","    return image\n","\n","gr.Interface(\n","    fn=generate,\n","    inputs=gr.Textbox(label=\"Describe your room\"),\n","    outputs=\"image\",\n","    title=\"Room Decor Generator\"\n",").launch()\n"]},{"cell_type":"markdown","metadata":{"id":"UA0ulAPvE_MP"},"source":["#2. Milestone 2"]},{"cell_type":"markdown","metadata":{"id":"MOqo8WpjEtnP"},"source":["##4. Integrate text encoder (CLIP/BERT) with diffusion model (Stable Diffusion / DDPM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_DwZlS1HtAV"},"outputs":[],"source":["!pip install -q torch torchvision diffusers transformers accelerate safetensors numpy\n","\n","import torch, numpy as np, os, json\n","from diffusers import StableDiffusionPipeline\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"]},{"cell_type":"markdown","metadata":{"id":"PnSJ_ysfih5q"},"source":["1. Loading pipeline with CLIP Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMekb9qvHtAV"},"outputs":[],"source":["pipe = StableDiffusionPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",").to(device)\n","\n","tokenizer = pipe.tokenizer\n","text_encoder = pipe.text_encoder\n","print(\"Tokenizer & CLIP encoder loaded\")"]},{"cell_type":"markdown","metadata":{"id":"_OiYueb-ibnp"},"source":["2. Generator or Encoding Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xYNNUh2HtAV"},"outputs":[],"source":["@torch.no_grad()\n","def encode_prompts(\n","    prompts,\n","    neg_prompts=None,\n","    device=device,\n","    max_length=77\n","):\n","    if neg_prompts is None:\n","        neg_prompts = [\"\"] * len(prompts)\n","\n","    # Tokenize into (batch, seq_len=77)\n","    text_inputs = tokenizer(\n","        prompts,\n","        padding=\"max_length\",\n","        max_length=max_length,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","    )\n","\n","    neg_inputs = tokenizer(\n","        neg_prompts,\n","        padding=\"max_length\",\n","        max_length=max_length,\n","        truncation=True,\n","        return_tensors=\"pt\",\n","    )\n","\n","    # CLIP text encoder ‚Üí (batch, 77, 768)\n","    prompt_embeds = text_encoder(text_inputs.input_ids.to(device))[0]\n","    neg_embeds    = text_encoder(neg_inputs.input_ids.to(device))[0]\n","\n","    # Match UNet dtype\n","    dtype = pipe.unet.dtype\n","    prompt_embeds = prompt_embeds.to(dtype)\n","    neg_embeds    = neg_embeds.to(dtype)\n","\n","    return prompt_embeds, neg_embeds"]},{"cell_type":"markdown","metadata":{"id":"DuZT3icDivr1"},"source":["3. generating images using vecotor storage for embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mnfBMEAiHtAV"},"outputs":[],"source":["@torch.no_grad()\n","def generate_images_from_embeds(\n","    prompt_embeds,\n","    negative_prompt_embeds,\n","    guidance_scale=7.5,\n","    num_inference_steps=30,\n","    height=512,\n","    width=512,\n","    seed=42,\n","):\n","\n","    generator = torch.Generator(device=device).manual_seed(seed)\n","\n","    out = pipe(\n","        prompt_embeds=prompt_embeds,\n","        negative_prompt_embeds=negative_prompt_embeds,\n","        num_inference_steps=num_inference_steps,\n","        guidance_scale=guidance_scale,\n","        generator=generator,\n","        height=height,\n","        width=width,\n","        output_type=\"pil\",\n","    )\n","\n","    return out.images\n"]},{"cell_type":"markdown","metadata":{"id":"SXfYvXyPkhde"},"source":["4. Vector Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QC2q4GVdHtAW"},"outputs":[],"source":["def save_vector_store(prompts, prompt_embeds,\n","                      path_npz=\"data/vectorstore.npz\",\n","                      path_json=\"data/vectorstore_meta.json\"):\n","    os.makedirs(\"data\", exist_ok=True)\n","    np.savez_compressed(path_npz, embeddings=prompt_embeds.cpu().numpy())\n","    with open(path_json, \"w\") as f:\n","        json.dump({\"prompts\": prompts}, f, indent=2)\n","    print(\"Vectorstore saved ‚úî\")\n","\n","def load_vector_store(path_npz=\"data/vectorstore.npz\",\n","                      path_json=\"data/vectorstore_meta.json\"):\n","    meta = json.load(open(path_json))\n","    arr = np.load(path_npz)[\"embeddings\"]\n","    return meta[\"prompts\"], arr"]},{"cell_type":"markdown","metadata":{"id":"sFqk9AnckwUw"},"source":["5. Testing CLIP with diffusion model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c-a4SOwdHtAW"},"outputs":[],"source":["\n","prompts = [\n","    \"A simple kitchen with refrigerator and dining table and lamp\",\n","    \"A modern living room with a smart TV and white sofa\",\n","    \"A bedroom with two lamps and a study desk\",\n","    \"A dining space with chandelier and wooden chairs\",\n","    \"A minimalist studio apartment with indoor plants\"\n","]\n","\n","neg = [\"blurry, low quality, distorted\"] * len(prompts)\n","\n","# Encode embeddings\n","prompt_embeds, neg_embeds = encode_prompts(prompts, neg)\n","\n","# Check shapes (SHOULD BE: (5, 77, 768))\n","print(\"Prompt embed shape:\", prompt_embeds.shape)\n","print(\"Negative embed shape:\", neg_embeds.shape)\n","\n","# Save vectorstore\n","save_vector_store(prompts, prompt_embeds)\n","\n","# Generate images\n","os.makedirs(\"milestone2_outputs\", exist_ok=True)\n","\n","images = generate_images_from_embeds(prompt_embeds, neg_embeds)\n","\n","for i, img in enumerate(images):\n","    img.save(f\"milestone2_outputs/sample_{i+1}.png\")\n","    print(\"Saved image:\", f\"milestone2_outputs/sample_{i+1}.png\")"]},{"cell_type":"markdown","metadata":{"id":"WD0JPjEalMYs"},"source":["##5. Run baseline conditional generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewkCjafDHtAX"},"outputs":[],"source":["# ============================\n","# BASELINE CONDITIONAL GENERATION\n","# (Using pretrained Stable Diffusion)\n","# ============================\n","\n","!pip install -q diffusers transformers accelerate torch safetensors\n","\n","import torch\n","from diffusers import StableDiffusionPipeline\n","from PIL import Image\n","import os\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Load pretrained Stable Diffusion v1.5\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",").to(device)\n","\n","# Your 5 milestone prompts\n","prompts = [\n","    \"A simple kitchen with refrigerator and dining table and lamp\",\n","    \"A modern living room with a smart TV and white sofa\",\n","    \"A bedroom with two lamps and a study desk\",\n","    \"A dining space with chandelier and wooden chairs\",\n","    \"A minimalist studio apartment with indoor plants\"\n","]\n","\n","# Make output folder\n","os.makedirs(\"baseline_outputs\", exist_ok=True)\n","\n","# Generate baseline images\n","for i, prompt in enumerate(prompts):\n","    print(f\"Generating image {i+1}...\")\n","    image = pipe(prompt).images[0]\n","    image_path = f\"baseline_outputs/baseline_{i+1}.png\"\n","    image.save(image_path)\n","    print(\"Saved:\", image_path)\n","\n","print(\" Baseline conditional generation complete!\")\n"]},{"cell_type":"markdown","metadata":{"id":"IP6WwuJgmBY6"},"source":["##6. Tune classifier-free guidance + noise schedule"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlYxuNNGHtAX"},"outputs":[],"source":["!pip install -q diffusers transformers accelerate torch safetensors\n","\n","import torch\n","from diffusers import StableDiffusionPipeline\n","import os\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16 if device=='cuda' else torch.float32\n",").to(device)\n","\n","os.makedirs(\"cfg_scheduler_outputs\", exist_ok=True)\n"]},{"cell_type":"markdown","metadata":{"id":"XMbsxRMrmd-6"},"source":["2. Tuning Classifer free guidance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZfjumGbHtAY"},"outputs":[],"source":["prompts = [\n","    \"A simple kitchen with refrigerator and dining table and lamp\"\n","]\n","\n","cfg_values = [3, 5, 7.5, 10, 12]\n","\n","for cfg in cfg_values:\n","    print(f\"Generating CFG={cfg}...\")\n","    image = pipe(\n","        prompts[0],\n","        guidance_scale=cfg,\n","        num_inference_steps=30\n","    ).images[0]\n","\n","    filename = f\"cfg_scheduler_outputs/cfg_{cfg}.png\"\n","    image.save(filename)\n","    print(\"Saved:\", filename)\n"]},{"cell_type":"markdown","metadata":{"id":"vggZhBZQmkaK"},"source":["3. Tuning Diffusion free noise scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WFgCBZ6HtAY"},"outputs":[],"source":["from diffusers import (\n","    DDIMScheduler,\n","    EulerAncestralDiscreteScheduler,\n","    LMSDiscreteScheduler,\n","    PNDMScheduler\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAbQIvqPHtAY"},"outputs":[],"source":["schedulers = {\n","    \"PNDM\": PNDMScheduler.from_config(pipe.scheduler.config),\n","    \"DDIM\": DDIMScheduler.from_config(pipe.scheduler.config),\n","    \"EulerA\": EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config),\n","    \"LMS\": LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n","}\n","\n","for name, sched in schedulers.items():\n","    print(f\"Testing scheduler: {name}\")\n","    pipe.scheduler = sched\n","\n","    image = pipe(\n","        prompts[0],\n","        guidance_scale=7.5,  # keep constant\n","        num_inference_steps=30\n","    ).images[0]\n","\n","    filename = f\"cfg_scheduler_outputs/scheduler_{name}.png\"\n","    image.save(filename)\n","    print(\"Saved:\", filename)\n"]},{"cell_type":"markdown","metadata":{"id":"rRpMXXtNtgHy"},"source":["#4. Git Repository Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ud8b4AdeHtAY"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cnTFkzhHtAY"},"outputs":[],"source":["!mkdir -p /content/drive/MyDrive/generative-ai-room-decorator/{data/raw,notebooks,src,outputs,configs}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWYbm52OHtAY"},"outputs":[],"source":["!touch generative-ai-room-decorator/{README.md,.gitignore}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efrRjB2yHtAY"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GTmyGW3HtAY"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git init\n","!git remote add origin git@github.com:<username>/generative-ai-room-decorator.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqooDBkGHtAZ"},"outputs":[],"source":["!ssh-keygen -t ed25519 -C \"pillalamarri.v@northeastern.edu\"\n","\n","# 2Ô∏è‚É£ Start SSH agent and add key\n","!eval \"$(ssh-agent -s)\"\n","!ssh-add ~/.ssh/id_ed25519\n","\n","# 3Ô∏è‚É£ Show your public key\n","!cat ~/.ssh/id_ed25519.pub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3P8cmAKMHtAZ"},"outputs":[],"source":["!eval \"$(ssh-agent -s)\"    # start SSH agent\n","!ssh-add ~/.ssh/id_ed25519 # add your SSH key to the agent\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKMz8S8mHtAZ"},"outputs":[],"source":["!ssh -T git@github.com\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFXLm_mLHtAZ"},"outputs":[],"source":["# === START: SSH Agent and Key Setup ===\n","\n","# Start SSH agent and add key in one shell session\n","!eval \"$(ssh-agent -s)\"\n","!ssh-add ~/.ssh/id_ed25519\n","\n","# Add GitHub to known_hosts (avoids \"host key verification failed\")\n","!mkdir -p ~/.ssh\n","!ssh-keyscan github.com >> ~/.ssh/known_hosts\n","\n","# Set correct permissions\n","!chmod 700 ~/.ssh\n","!chmod 644 ~/.ssh/known_hosts\n","\n","# Test SSH connection\n","!ssh -T git@github.com\n","# === END ===\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIQELJaOHtAZ"},"outputs":[],"source":["!git remote -v\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"me5_9tfrHtAZ"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ntE9ToTjHtAZ"},"outputs":[],"source":["!git rebase --abort\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Mj8OxelHtAZ"},"outputs":[],"source":["!git status\n","!git branch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fTmX0xfHtAZ"},"outputs":[],"source":["!git switch -C main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNm52_ayHtAZ"},"outputs":[],"source":["!git remote remove origin\n","!git remote add origin git@github.com:PVRPratyusha/generative-ai-room-decorator.git\n","!git fetch origin\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoDI_KVVHtAZ"},"outputs":[],"source":["!git add .\n","!git commit -m \"Clean branch reset after rebase issue\"\n","!git push origin main --force\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mkC0aFiHtAZ"},"outputs":[],"source":["!echo \".ipynb_checkpoints/\" >> .gitignore\n","!git add .gitignore\n","!git commit -m \"Ignore Colab checkpoint files\"\n","!git push origin main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nM_-xRygHtAZ"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator/notebooks\n","!cp Generative_Project_Milestone_1.ipynb Generative_Project_Milestone_1_broken_backup.ipynb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syZFe0MHHtAa"},"outputs":[],"source":["# from google.colab import files\n","# uploaded = files.upload()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGG1lAetHtAa"},"outputs":[],"source":["!mv \"/content/generative_project_milestone_1.py\" \"/content/drive/MyDrive/generative-ai-room-decorator/notebooks/\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Amx60CFkHtAa"},"outputs":[],"source":["!ls /content\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MEzT68NzHtAa"},"outputs":[],"source":["!ls \"/content/drive/MyDrive/generative-ai-room-decorator/notebooks\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dDyQTuPhHtAa"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git add notebooks/generative_project_milestone_1.py\n","!git commit -m \"Re-upload working Milestone 1 notebook\"\n","!git push origin main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IUAHSalHtAa"},"outputs":[],"source":["!touch data/.gitkeep\n","!touch src/.gitkeep\n","!touch outputs/.gitkeep\n","!touch configs/.gitkeep\n","\n","%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git add .\n","!git commit -m \"Add placeholder files to show folder structure\"\n","!git push origin main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gTP3OgaHtAa"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NjYNU6hHtAa"},"outputs":[],"source":["!git rm notebooks/Generative_Project_Milestone_1\\ \\(1\\).ipynb \\\n","        notebooks/Generative_Project_Milestone_1\\ \\(2\\).ipynb \\\n","        notebooks/Generative_Project_Milestone_1.ipynb \\\n","        notebooks/Generative_Project_Milestone_1_broken_backup.ipynb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drD4-6vsHtAa"},"outputs":[],"source":["!git commit -m \"Remove redundant and corrupted notebook files\"\n","!git push origin main\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wp2G3g81HtAa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"IjJl82bnvDb-"},"source":["#Git Push for Milestone 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZPJydREHtAa"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBYZcp7AHtAa"},"outputs":[],"source":["!git remote -v\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyPkb5u9HtAa"},"outputs":[],"source":["!git config --global user.email \"pillalamarri.v@northeastern.edu\"\n","!git config --global user.name \"PVRPratyusha\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4EFBQj1HtAa"},"outputs":[],"source":["!git checkout -b milestone2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHN_kayGHtAa"},"outputs":[],"source":["!git remote add origin https://<REMOVED>@github.com/PVRPratyusha/generative-ai-room-decorator.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TdJEcEN4HtAa"},"outputs":[],"source":["!git remote remove origin\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyGy_0nrHtAa"},"outputs":[],"source":["# ============================\n","# 0Ô∏è‚É£  GO TO YOUR PROJECT FOLDER\n","# ============================\n","%cd /content/drive/MyDrive/generative-ai-room-decorator\n","\n","# ============================\n","# 1Ô∏è‚É£  RE-INITIALIZE GIT SAFELY\n","# ============================\n","!rm -rf .git\n","!git init\n","\n","# Set your identity\n","!git config --global user.email \"pillalamarri.v@northeastern.edu\"\n","!git config --global user.name \"PVRPratyusha\"\n","\n","# ============================\n","# 2Ô∏è‚É£  ADD REMOTE (HTTPS + TOKEN)\n","# ============================\n","# üî¥ Replace YOUR_GITHUB_TOKEN_HERE\n","git remote add origin <REMOVED FOR SECURITY>\n","\n","\n","# Confirm remote\n","!git remote -v\n","\n","# ============================\n","# 3Ô∏è‚É£  CREATE NEW BRANCH ONLY FOR MILESTONE 2\n","# ============================\n","!git checkout -b milestone2-colab\n","\n","# ============================\n","# 4Ô∏è‚É£  ADD SEPARATE README FOR THIS BRANCH\n","# ============================\n","!echo \"# Milestone 2 Work (Colab Branch)\" > README_milestone2.md\n","\n","# ============================\n","# 5Ô∏è‚É£  ADD ALL PROJECT FILES\n","# ============================\n","!git add .\n","!git commit -m \"Milestone 2: Add full project structure + separate README for branch\"\n","\n","# ============================\n","# 6Ô∏è‚É£  PUSH ONLY THIS BRANCH\n","# ============================\n","!git push -u origin milestone2-colab\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlvqW-VTHtAb"},"outputs":[],"source":["!ls /content\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_xZjp33HtAb"},"outputs":[],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aGJrOl3YHtAb"},"outputs":[],"source":["!find /content -name \"*Milestone_2*.ipynb\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6REPUkkHtAb"},"outputs":[],"source":["!find /content/drive -name \"*Milestone_2*.ipynb\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G-P8SHDHtAb"},"outputs":[],"source":["!find / -name \"*Milestone_2*.ipynb\" 2>/dev/null\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7OOOyVnHtAb"},"outputs":[],"source":["!mv \"/content/drive/MyDrive/Colab Notebooks/Generative_Project_Milestone_2.ipynb\" \"/content/drive/MyDrive/generative-ai-room-decorator/notebooks/\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTfSreQCHtAb"},"outputs":[],"source":["!ls \"/content/drive/MyDrive/generative-ai-room-decorator/notebooks/\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2wA2KcGEHtAb"},"outputs":[],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git reset --soft HEAD~1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2D5D-VyHtAb"},"outputs":[],"source":["!git add notebooks/Generative_Project_Milestone_2.ipynb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTdp-a4qHtAb"},"outputs":[],"source":["!git commit -m \"Add Milestone 2 notebook (token removed)\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PqEke43OHtAb"},"outputs":[],"source":["!git push origin milestone2-colab\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRAZxFGcHtAb","executionInfo":{"status":"ok","timestamp":1763337801514,"user_tz":300,"elapsed":9006,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"1888bd4d-be9c-4fcc-9a3b-6181492c3312"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/generative-ai-room-decorator\n","M\tnotebooks/Generative_Project_Milestone_2.ipynb\n","Already on 'milestone2-colab'\n","Your branch is ahead of 'origin/milestone2-colab' by 2 commits.\n","  (use \"git push\" to publish your local commits)\n","fatal: ambiguous argument 'main': unknown revision or path not in the working tree.\n","Use '--' to separate paths from revisions, like this:\n","'git <command> [<revision>...] -- [<file>...]'\n"]}],"source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git checkout milestone2-colab\n","!git reset --hard main\n"]},{"cell_type":"code","source":["!git checkout milestone2-colab\n","!git rm -r --cached .\n","!git clean -fd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6PiUtIxH2t_","executionInfo":{"status":"ok","timestamp":1763337870763,"user_tz":300,"elapsed":1154,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"b879450f-c317-46d6-a36c-0431b93036ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["M\tnotebooks/Generative_Project_Milestone_2.ipynb\n","Already on 'milestone2-colab'\n","Your branch is ahead of 'origin/milestone2-colab' by 2 commits.\n","  (use \"git push\" to publish your local commits)\n","rm '.gitignore'\n","rm 'README_milestone2.md'\n","rm 'configs/.gitkeep'\n","rm 'data/.gitkeep'\n","rm 'notebooks/Generative_Project_Milestone_2.ipynb'\n","rm 'notebooks/generative_project_milestone_1.py'\n","rm 'outputs/.gitkeep'\n","rm 'src/.gitkeep'\n","Removing .gitignore\n","Removing README_milestone2.md\n","Removing configs/\n","Removing data/\n","Removing notebooks/\n","Removing outputs/\n","Removing src/\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"pillalamarri.v@northeastern.edu\"\n","!git config --global user.name \"PVRPratyusha\"\n"],"metadata":{"id":"KUNZ5ZkwIg6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global --list\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aBcPORJYIjRw","executionInfo":{"status":"ok","timestamp":1763337976401,"user_tz":300,"elapsed":130,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"7771deca-1b1f-4a1f-d507-574b80c3b8b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["user.email=pillalamarri.v@northeastern.edu\n","user.name=PVRPratyusha\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git add .\n","!git commit -m \"Rebuilt Milestone 2 branch with clean history (no secrets)\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsflCNiCIJi4","executionInfo":{"status":"ok","timestamp":1763337992565,"user_tz":300,"elapsed":3676,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"3ad1f3e4-aeff-4197-bbe7-b047ab22cb50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/generative-ai-room-decorator\n","[milestone2-colab 5a2784c] Rebuilt Milestone 2 branch with clean history (no secrets)\n"," 8 files changed, 1659 deletions(-)\n"," delete mode 100644 .gitignore\n"," delete mode 100644 README_milestone2.md\n"," delete mode 100644 configs/.gitkeep\n"," delete mode 100644 data/.gitkeep\n"," delete mode 100644 notebooks/Generative_Project_Milestone_2.ipynb\n"," delete mode 100644 notebooks/generative_project_milestone_1.py\n"," delete mode 100644 outputs/.gitkeep\n"," delete mode 100644 src/.gitkeep\n"]}]},{"cell_type":"code","source":["!git push origin --delete milestone2-colab\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cY4mHv2qIRMC","executionInfo":{"status":"ok","timestamp":1763338146474,"user_tz":300,"elapsed":558,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"13030c8f-715b-47f4-9c57-ed3a895f3f1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["error: unable to delete 'milestone2-colab': remote ref does not exist\n","\u001b[31merror: failed to push some refs to 'https://github.com/PVRPratyusha/generative-ai-room-decorator.git'\n","\u001b[m"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!git push origin milestone2-colab --force\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HeqpkmMnIqM7","executionInfo":{"status":"ok","timestamp":1763338150056,"user_tz":300,"elapsed":1110,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"e16e3a76-d9de-4f3f-f4c6-cf0a1261a615"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/generative-ai-room-decorator\n","Enumerating objects: 18, done.\n","Counting objects: 100% (18/18), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (13/13), done.\n","Writing objects: 100% (18/18), 585.98 KiB | 4.51 MiB/s, done.\n","Total 18 (delta 4), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (4/4), done.\u001b[K\n","remote: \u001b[1;31merror\u001b[m: GH013: Repository rule violations found for refs/heads/milestone2-colab.\u001b[K\n","remote: \n","remote: - GITHUB PUSH PROTECTION\u001b[K\n","remote:   ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\u001b[K\n","remote:     Resolve the following violations before pushing again\u001b[K\n","remote: \n","remote:     - Push cannot contain secrets\u001b[K\n","remote: \n","remote:     \u001b[K\n","remote:      (?) Learn how to resolve a blocked push\u001b[K\n","remote:      https://docs.github.com/code-security/secret-scanning/working-with-secret-scanning-and-push-protection/working-with-push-protection-from-the-command-line#resolving-a-blocked-push\u001b[K\n","remote:     \u001b[K\n","remote:     \u001b[K\n","remote:       ‚Äî‚Äî GitHub Personal Access Token ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\u001b[K\n","remote:        locations:\u001b[K\n","remote:          - commit: cbe303b3f548d6250808ed15025c062ce9d49ce7\u001b[K\n","remote:            path: notebooks/Generative_Project_Milestone_2.ipynb:1\u001b[K\n","remote:          - commit: cbe303b3f548d6250808ed15025c062ce9d49ce7\u001b[K\n","remote:            path: notebooks/Generative_Project_Milestone_2.ipynb:1\u001b[K\n","remote:          - commit: cbe303b3f548d6250808ed15025c062ce9d49ce7\u001b[K\n","remote:            path: notebooks/Generative_Project_Milestone_2.ipynb:1\u001b[K\n","remote:          - commit: cbe303b3f548d6250808ed15025c062ce9d49ce7\u001b[K\n","remote:            path: notebooks/Generative_Project_Milestone_2.ipynb:1\u001b[K\n","remote:          - commit: 1e411c5918a49493117d72009beeb589f73e4463\u001b[K\n","remote:            path: notebooks/Generative_Project_Milestone_2.ipynb:1174\u001b[K\n","remote:     \u001b[K\n","remote:        (?) To push, remove secret from commit(s) or follow this URL to allow the secret.\u001b[K\n","remote:        https://github.com/PVRPratyusha/generative-ai-room-decorator/security/secret-scanning/unblock-secret/35a9UZMKy6mkxk1D4NlNmRoFwOu\u001b[K\n","remote:     \u001b[K\n","remote: \n","remote: \n","To https://github.com/PVRPratyusha/generative-ai-room-decorator.git\n"," \u001b[31m! [remote rejected]\u001b[m milestone2-colab -> milestone2-colab (push declined due to repository rule violations)\n","\u001b[31merror: failed to push some refs to 'https://github.com/PVRPratyusha/generative-ai-room-decorator.git'\n","\u001b[m"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/generative-ai-room-decorator\n","!ls -R\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhDAa45FJyy3","executionInfo":{"status":"ok","timestamp":1763338350438,"user_tz":300,"elapsed":113,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"82ddfe97-30d8-4580-94fb-fda500bbe25d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/generative-ai-room-decorator\n",".:\n"]}]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"generative-ai-room-decorator*\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqDaU5jtJ-5j","executionInfo":{"status":"ok","timestamp":1763338407592,"user_tz":300,"elapsed":11889,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"59337664-539b-44aa-d713-b7045251c2f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/generative-ai-room-decorator\n"]}]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -name \"generative_project_milestone_1.py\"\n"],"metadata":{"id":"DgCf779iKJ-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -name \"Generative_Project_Milestone_2.ipynb\"\n"],"metadata":{"id":"mC0C28yaKS5j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -name \".gitkeep\"\n"],"metadata":{"id":"dif-I3zCKVaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"configs\"\n","!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"notebooks\"\n","!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"src\"\n","!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"data\"\n","!find \"/content/drive/MyDrive\" -maxdepth 4 -type d -name \"outputs\"\n"],"metadata":{"id":"NxLVm7qhKXyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"*.py\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"*.ipynb\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"Generative*Milestone*\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"*.gitkeep\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lp1mkz2bKaWH","executionInfo":{"status":"ok","timestamp":1763338684717,"user_tz":300,"elapsed":938,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"b1e0506c-a014-4ce5-d8eb-eb75a5791d7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Copy of Lab1_Features.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Module1_Lab1_0473.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Module1_Lab1_fmml20210473.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Mod2_Lab1_fmml20210468.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of FMML_CLF1_Lab1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of FMML_CLF1_Lab2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Project_FMML_CLF1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Build_a_food_image_classifier.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Heart Attack -updated.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Heart_Attack_analysis.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of NewsSentiment.ipynb\n","/content/drive/MyDrive/Colab Notebooks/NewsSentiment.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_Mod4_Lab2 (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_Mod4_Lab3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_Mod4_Lab2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Module4_SVM_Lab4_FMML20210473.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473-ClassificationII-Lab1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of FMML-ClassificationII-Lab4-GiniImpurity_Generalizability.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473-ClassificationII-Lab4-EnsembleMethods.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_ Module 4 Project.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of regression-lab1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210468_MODULE6_ regression-lab1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_MOD 6_ regression-lab1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Copy of Regression_Project.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Regression_Project2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Group31_ Covid_Data_Analysis.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Covid_Data_Analysis_Pratyusha.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473_regression-lab2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Covid_data_analysis.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FMML20210473 Course: Lab 1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/P Venkata Raja Pratyusha_Task1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/ P Venkata Raja Pratyusha_Task2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/P_Venkata_Raja_Pratyusha_Task2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled11.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Covid_Data_Analysis.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of zs_v2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled0.ipynb\n","/content/drive/MyDrive/Colab Notebooks/LLAMA_Testing.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Converting_PDF_to_text.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of llama-2-7b-chat.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FamNeeds_App.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Quiz1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled4.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Dataprepforviz (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled5.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Dataprepforviz.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Lecture4_STUDENT (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Lecture3_FDA.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Lecture5_STUDENT (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled6.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Quiz2_.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Lecture4_STUDENT.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Lecture5_STUDENT.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Project1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Untitled7.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FDA_Project1_13102024.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled7.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Project-1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled18.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Special_Applications.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6600_Assignment3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of IE6600_Assignment3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6600_Project2 (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/FDA_Project_3_CHB-MIT_EEG_Database.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled8.ipynb\n","/content/drive/MyDrive/Colab Notebooks/FDA_Project_3_BON_EEG_Database.ipynb\n","/content/drive/MyDrive/Colab Notebooks/EEG Classification Model.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled9.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Project3_EEG_Classification.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Project3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6400_Project3_EEG_Classification-2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled10.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE6600_Project2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled12.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Homework 1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Homework_1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Gymnasium_Tutorial (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Gymnasium_Tutorial.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Python_code_ch3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled13.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Data_Exploration_Visualization.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Data_Exploration_Visualization_Updated.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Data_Exploration_Visualization_Final.ipynb\n","/content/drive/MyDrive/Colab Notebooks/DMA_Chapter5.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE7275_Chapter7.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Pytorch Lab (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Pytorch_Lab.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Pytorch_Lab_Pratyusha_PVR.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled14.ipynb\n","/content/drive/MyDrive/Colab Notebooks/IE7275_Homework_3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Data_preprocessing.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled15.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Language Model (Like ChatGPT!) From Scratch ‚Äì Part I.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Theory_and_Practical_Applications_of_AI_Generative_Modeling_Assignment_1-2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/CSYE7380_Assignment2.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Travel Itinerary Project.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled16.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled33.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled17.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Final_PRject_GenAI (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Copy of Final_PRject_GenAI.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled19.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Final_Project_GenAI_Aug_8th-3 (1).ipynb\n","/content/drive/MyDrive/Colab Notebooks/Final_Project_GenAI_Aug_8th-3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/GC_Streamlit_Lab.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Face_Detection_Project.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled20.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled21.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Untitled22.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Asn2_IE76150_v1.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Milestone_3.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Milestone_1_face_Recog.ipynb\n","/content/drive/MyDrive/Colab Notebooks/Document_scan_test.ipynb\n","/content/drive/MyDrive/Colab Notebooks/run_colab_backend.ipynb\n","/content/drive/MyDrive/Generative_Project_Milestone_1.ipynb\n","/content/drive/MyDrive/Generative_Project_Milestone_1.ipynb\n"]}]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"*Milestone_2*.ipynb\"\n"],"metadata":{"id":"NgX00k3eLPt6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 5 -type d -name \"configs\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type d -name \"src\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type d -name \"notebooks\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type d -name \"data\"\n","!find \"/content/drive/MyDrive\" -maxdepth 5 -type d -name \"outputs\"\n"],"metadata":{"id":"zAKt4DbILgzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!find \"/content/drive/MyDrive\" -maxdepth 5 -type f -name \"Generative_Project_Milestone2.ipynb\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nw0puYY0Lidb","executionInfo":{"status":"ok","timestamp":1763338918092,"user_tz":300,"elapsed":118,"user":{"displayName":"pratyusha pvr","userId":"11357082479560919097"}},"outputId":"55e99868-36f2-4638-f9bf-f1899daca80e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["find: ‚Äò/content/drive/MyDrive‚Äô: No such file or directory\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CKF7NGDWLvRM"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1OQTc7jB4pWl6d_0xOer5PF3ZXXWYgdLQ","timestamp":1763338823171}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}